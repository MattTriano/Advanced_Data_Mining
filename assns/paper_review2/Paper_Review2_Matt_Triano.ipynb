{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC529 Paper Review 2\n",
    "## Matt Triano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: The problem of Multi-Label Learning\n",
    "\n",
    "Multi-label learning involves taking data sets where each sample can have a set of multiple labels rather than a single label. For example, in a data set of songs, each song can belong to multiple genres or just a single genre. If there are 5 distinct labels, $A,B,C,D$ and $E$ (and assume that all samples must have at least 1 label), then there are $5 \\times 5 \\times 4 \\times 3 \\times 2 = 600 $ possible combinations of labels (namely all 5 label options times (4 label options and null) times (3 labels and null) ...). This both drastically reduces the number of training samples for any given class and as 5 is extremely small (how many distinct music genres exist?) demonstrates that this can quickly become extremely computationally expensive. That is the problem addressed by the algorithm in this paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Novelty of the New Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior strategies for addressing the problem of multi-learning consisted of **first order** approaches, **second order** approaches, and **higher order** approaches. \n",
    "* **First order** approaches try to learn by building an ensemble of binary classifiers in a one-versus-rest style, but this ignores the correlations between different labels which disregards valuable information and empirically produces lower generalizability to new data than other approaches.  \n",
    "* **Second order** approaches postulate that there are significant pairwise relations and looks at, for example, the the frequency with which pairs of labels occur together (co-occur) or are absent together, and while this can produce more accurate multi-label learners, it still ignores higher order correlations and it produces highly complex models.\n",
    "* **Higher order** approaches look for higher order relations between different subsets of the available labels, either by considering the influence of all labels on all other labels, or by just assembling ensembles that look at correlations between random label subsets. These methods also produce very complex models and are either very computationally expensive, unable to identify substructures (like hierarchical label groups), or may fail to find relevant combinations because there is a massive number of combinations and randomly searching is very inefficient in those conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper explores the novel approach of using a **Bayesian Network** or **Directed Acyclic Graph** (**DAG**) to represent the joint probability of label co-occurrence, and then building a binary classifier for each label that uses the set of parental labels that label as additional features.\n",
    "\n",
    "This produces a far more compact model that explicitly captures any order of relationship structure in the very existence of links on the graph.\n",
    "\n",
    "To identify the links/relationships needed to build the DAG, the authors reason that the baseline effect of the set of all features can be separated out from classifiers for each label, and then by using the assumption that residual errors will independent for labels that are independent, they can identify labels that are conditionally independent (ie labels that should not have a link in the DAG) by building an independent classifier for each label and comparing error terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Data Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors used 14 multi-label data sets to evaluate their algorithm. Seven of these datasets are 'regular scale' and the other seven are 'large scale'. \n",
    "\n",
    "The 'regular scale' data set sample sizes ranged from $593 \\leq |\\mathcal{S}| \\leq 2417$ samples, had between (inclusive) $72$ and $1449$ features, and had between (inclusive) $5$ and $53$ possible labels. Three of these data sets consisted of nominal features and four data sets consisted of numerical features. These data sets were from the domains of music, media (2x), text (2x),  and biology (2x).\n",
    "\n",
    "The 'large scale' data set sample sizes ranged from $6000 \\leq |\\mathcal{S}|\\leq 28596$ samples, had between (inclusive) $944$ and $1836$ features, and had between (inclusive) $22$ and $159$ possible labels, but they did use dimensionality reduction on six of those seven data sets. Five of those data sets consisted of numerical features and two data sets consisted of nominal data. All seven of these data sets were text based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their models were evaluated using five metrics designed for multi-label learning. Those metrics are: \n",
    "\n",
    "* The **Hamming loss function**, which appears to report the sum of the ratios of [the differences between the predicted labels ($h(x_I)$) to the vector of true labels ($Y_i$)] over the number of possible labels ($|\\mathcal{Y}|$).\n",
    "$$\\text{hloss}_{\\mathcal{S}}(h) = \\frac{1}{p}\\sum^p_{i=1}\\frac{1}{|\\mathcal{Y}|}h(x_i)\\Delta Y_i$$\n",
    "\n",
    "* **One-Error**, which evaluates how many times the most strongly predicted label is not in the set of true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Coverage**, which evaluates how far down the list of predicted labels (sorted by strength of prediction) before every true label is included (even if many false labels are also included).\n",
    "\n",
    "* **Ranking Loss**, which evaluates the average percent of label pairs that are incorrectly ranked or ordered.\n",
    "\n",
    "* And **Average Precision**, which computes the percent of true labels ranked above each particular label and averages all of those percents to see how relevant the rankings are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: My Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I had a bit of trouble conceptualizing this algorithm, but as I forced my self to play with their equations and write out what the variables meant, it became clearer. I really like the idea of using graphs to represent complex systems (so many real human systems consist of networks with structured relationships, like social networks where hidden factors like employer, school, specific hobbies drive patterns in joint graph membership), but I hadn't really thought about using Bayesian networks outside of simple game theory though experiments. I also hadn't thought to approach the problem from the angle these researchers took, namely rather than to assume no links and try to find them, they assumed all links and looked at error rates to see which links should be removed."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
