{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import copy\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from IPython.display import display\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Mg',\n",
       "       'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
       "       'Proanthocyanins', 'Color intensity', 'Hue',\n",
       "       'OD280/OD315 of diluted wines', 'Proline'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash   Mg  Total phenols  \\\n",
       "0      1    14.23        1.71  2.43               15.6  127           2.80   \n",
       "1      1    13.20        1.78  2.14               11.2  100           2.65   \n",
       "2      1    13.16        2.36  2.67               18.6  101           2.80   \n",
       "3      1    14.37        1.95  2.50               16.8  113           3.85   \n",
       "4      1    13.24        2.59  2.87               21.0  118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280/OD315 of diluted wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data set and splitting off the target feature, 'Class'\n",
    "wine_df = pd.read_csv(\"wine.csv\")\n",
    "wine_class_df = wine_df['Class']\n",
    "wine_data_df = wine_df.drop('Class', axis=1)\n",
    "display(wine_df.columns)\n",
    "wine_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92975, 58067, 34086, 60620, 89460, 82584, 32399, 55985, 41239,\n",
       "        9449, 23706,  8222, 97963, 33950, 40684,  8060, 73498, 79222,\n",
       "       79728, 73180, 93509, 93520, 49398, 68094, 36271,  3824, 22267,\n",
       "       21580, 80165, 77734])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a consistent set of random seeds, so that my results are reproducible\n",
    "rng = np.random.RandomState(1234)\n",
    "random_seeds = rng.randint(low=0, high=99999, size=30)\n",
    "random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f85d86e81f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# help(stats.t.ppf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt_crit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.975\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0merr_margin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_crit\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0merr_margin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# help(stats.t.ppf)\n",
    "tmp = pd.Series(tree_acc)\n",
    "t_crit = stats.t.ppf(0.975, tmp)\n",
    "err_margin = t_crit * tmp.std() / (len(tmp) ** 0.5)\n",
    "err_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function compares 2 classifiers\n",
    "def clf_comparison(clf1, clf1_name, clf2, clf2_name, data_df, class_df, test_size=0.34, n_trials=30, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    random_seeds = rng.randint(low=0, high=99999, size=n_trials)\n",
    "    clf1_acc = [];       clf2_acc = []\n",
    "    clf1_resub_acc = []; clf2_resub_acc = []\n",
    "    clf1_gen_acc = [];   clf2_gen_acc = []\n",
    "    for i in range(n_trials):\n",
    "        data_train, data_test, class_train, class_test = train_test_split(data_df, class_df, test_size=test_size,\n",
    "                                                                      random_state=random_seeds[i])\n",
    "        clf1_acc.append(clf_evaluation(clf1, data_train, data_test, class_train, class_test))\n",
    "        clf2_acc.append(clf_evaluation(clf2, data_train, data_test, class_train, class_test))\n",
    "    clf1_resub, clf1_gen = resub_and_gen_errors(clf1, data_train, data_test, class_train, class_test)\n",
    "    clf2_resub, clf2_gen = resub_and_gen_errors(clf2, data_train, data_test, class_train, class_test)\n",
    "    clf1_resub_acc.append(clf1_resub)\n",
    "    clf2_resub_acc.append(clf2_resub)\n",
    "    clf1_gen_acc.append(clf1_gen)\n",
    "    clf2_gen_acc.append(clf2_gen)\n",
    "    mean_var_CI_calculator(clf1_name, pd.Series(clf1_acc), test_size)\n",
    "    mean_var_CI_calculator(clf2_name, pd.Series(clf2_acc), test_size)\n",
    "    mean_var_CI_calculator(\"Difference of \" + clf1_name + \" and \" + clf2_name,\n",
    "                           (pd.Series(clf1_acc)-pd.Series(clf2_acc)).abs(),0.34)\n",
    "    return clf1_acc, clf2_acc, clf1_resub_acc, clf2_resub_acc, clf1_gen_acc, clf2_gen_acc\n",
    "                        \n",
    "# This executes a simple fit-predict-evaluate routine with a single data split.\n",
    "# classifier:   a classifier model that conforms to sklearns regular classifier interface\n",
    "# data/class_train/test: array-like containers holding corresponding data and class labels\n",
    "def clf_evaluation(classifier, data_train, data_test, class_train, class_test):\n",
    "    clf_fit = classifier.fit(data_train, class_train)\n",
    "    clf_pred = classifier.predict(data_test)\n",
    "    return accuracy_score(class_test, clf_pred)\n",
    "\n",
    "def resub_and_gen_errors(classifier, data_train, data_test, class_train, class_test):\n",
    "    classifier.fit(data_train, class_train)\n",
    "    resub_err = classifier.score(data_train, class_train)\n",
    "    gen_err = classifier.score(data_test, class_test)\n",
    "    return resub_err, gen_err\n",
    "\n",
    "# This calculates the mean accuracy, variance, and confidence interval and prints it\n",
    "def mean_var_CI_calculator(clf_name, clf_acc, test_size):\n",
    "    sample_mean = clf_acc.mean()\n",
    "    sample_var = clf_acc.var()\n",
    "    sample_std = clf_acc.std()\n",
    "    sample_size = len(clf_acc)\n",
    "    z_crit = stats.norm.ppf(0.975)  # we're using 30 data points, so it's fair to assume a normal distribution\n",
    "    err_margin = z_crit * sample_std / (sample_size ** 0.5)\n",
    "    print(\"Accuracy statistics For classifier: \" + clf_name + \" with \"\n",
    "          + str(test_size) + \"% holdout for testing\")\n",
    "    print(\"- Sample Size: {:5d}\".format(sample_size))\n",
    "    print(\"- Variance: {:5f}\".format(sample_var))\n",
    "    print(\"- StdDev: {:5f}\".format(sample_std))\n",
    "    print(\"- Mean:{:>12.5f} +/- {:0.5f}\".format(sample_mean, err_margin))\n",
    "    print(\"- 95% CI =   [{:0.4f}, {:0.4f}]\\n\".format(sample_mean-err_margin, sample_mean+err_margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the Decision Tree Classifier parameters found via a GridSearch\n",
    "#   over 10 models and used for assignment 1\n",
    "tree_clf = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                            max_depth=3,\n",
    "                                            min_samples_leaf=2,\n",
    "                                            min_samples_split=2,\n",
    "                                            random_state=1234)\n",
    "\n",
    "nb_gauss_clf = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy statistics For classifier: tree_clf with 0.34% holdout for testing\n",
      "- Sample Size:    30\n",
      "- Variance: 0.000921\n",
      "- StdDev: 0.030345\n",
      "- Mean:     0.91421 +/- 0.01086\n",
      "- 95% CI =   [0.9033, 0.9251]\n",
      "\n",
      "Accuracy statistics For classifier: nb_gauss_clf with 0.34% holdout for testing\n",
      "- Sample Size:    30\n",
      "- Variance: 0.000229\n",
      "- StdDev: 0.015129\n",
      "- Mean:     0.96885 +/- 0.00541\n",
      "- 95% CI =   [0.9634, 0.9743]\n",
      "\n",
      "Accuracy statistics For classifier: Difference of tree_clf and nb_gauss_clf with 0.34% holdout for testing\n",
      "- Sample Size:    30\n",
      "- Variance: 0.000785\n",
      "- StdDev: 0.028011\n",
      "- Mean:     0.05464 +/- 0.01002\n",
      "- 95% CI =   [0.0446, 0.0647]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_acc, nb_gauss_acc, tree_resub_acc, nb_resub_acc, tree_gen_acc, nb_gen_acc = clf_comparison(tree_clf,\n",
    "                                                                                                \"tree_clf\",\n",
    "                                                                                                nb_gauss_clf,\n",
    "                                                                                                \"nb_gauss_clf\",\n",
    "                                                                                                wine_data_df,\n",
    "                                                                                                wine_class_df,\n",
    "                                                                                                0.34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions above used the same training and testing subsets to build a model for each classifier test the accuracy of both models. This process was repeated 30 times and the model accuracies were recorded to lists for their respective classifier. Then I calculated the above descriptive statistics for the both lists of accuracy values. \n",
    "\n",
    "To determine whether there's a statistically significant difference between the accuracies for these models, we'll perform a hypothesis test, and as we have 30 pairs (which is considered the lower bound for performing large-sample hypothesis tests) we'll perform a small-sample hypothesis test using Student's t-statistic. \n",
    "\n",
    "The small-sample hypothesis test for paired population means (ie the paired t-test) is given by the equation below\n",
    "\n",
    "$$t = \\frac{\\bar{x}_d-D_0}{\\frac{s_d}{\\sqrt{n_d}}}$$\n",
    "\n",
    "For our classifier accuracy data: \n",
    "* sample size $=n_d=30$ paired samples \n",
    "* sample mean difference        $\\bar{x}_d = 0.05464$ \n",
    "* Sample Stdev of diffs         $s_d = 0.02801$\n",
    "* Expected mean difference      $D_0$\n",
    "\n",
    "The null hypothesis ($H_0$) is that the mean accuracy for models is the same, (ie $H_0:\\mu_1 - \\mu_2 = D_0 0$), and the alternative hypotheses is that the accuracies differ (ie $H_a:\\mu_1 - \\mu_2 \\neq 0$).\n",
    "\n",
    "$$t=\\frac{(0.05464)-0}{\\frac{0.02801}{\\sqrt{30}}} = \\frac{(0.05464)-0}{0.00511} = 10.6846$$\n",
    "\n",
    "For $n=30$ and $\\alpha = 0.025$ (two tailed $95%$), the critical t value is 2.042. The calculated 10.6846 is far outside those bounds, so the difference in model accuracy is statistically significant.\n",
    "\n",
    "I also used the relative t-test evaluator in scipy's stats module, which calculated 10.6852, with a $p-val = 1.43 \\times 10^{-11}$, which matches the calculated result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.684598551261077"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_t = 0.05464/(0.02801/(30**0.5))\n",
    "paired_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=10.685187333241123, pvalue=1.4369053553409192e-11)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(nb_gauss_acc, tree_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# 2: Varying the Training-Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Build a loop where the test size is varied and capture the resub and gen accs\n",
    "splits = [0.75, 0.65, 0.55, 0.45, 0.35, 0.25, 0.15]\n",
    "tree_resub_acc_list = []; tree_gen_acc_list = []\n",
    "nb_resub_acc_list = []; nb_gen_acc_list = []\n",
    "\n",
    "for split in splits:\n",
    "    tree_acc, nb_gauss_acc, tree_resub_acc, nb_resub_acc, tree_gen_acc, nb_gen_acc = clf_comparison(tree_clf,\n",
    "                                                                                                \"tree_clf\",\n",
    "                                                                                                nb_gauss_clf,\n",
    "                                                                                                \"nb_gauss_clf\",\n",
    "                                                                                                wine_data_df,\n",
    "                                                                                                wine_class_df,\n",
    "                                                                                                0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
